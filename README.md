# ğŸ¦– Dino AI
## Alrotimo Evolutivo e Rede Neural Evolutiva para o Jogo do Dinossauro do Chrome

Este projeto implementa uma **InteligÃªncia Artificial Evolutiva** capaz de jogar um jogo inspirado no **Dinossauro do Google Chrome**.

O agente aprende exclusivamente por meio da interaÃ§Ã£o com o ambiente, utilizando **Redes Neurais** otimizadas por **Algoritmos Evolutivos**, sem regras predefinidas ou comportamentos prÃ©-programados.

> Os agentes sobrevivem, sÃ£o avaliados pelo desempenho e evoluem ao longo das geraÃ§Ãµes.

![DemonstraÃ§Ã£o do Jogo](Readme/Dino2.gif)
---

## ğŸ¯ Objetivo do Projeto

O objetivo principal Ã© estudar e aplicar conceitos de **ComputaÃ§Ã£o Evolutiva** em um ambiente de jogo em tempo real, com foco em:

- Tomada de decisÃ£o usando **Redes Neurais**
- Aprendizado por **Algoritmos Evolutivos**
- SeleÃ§Ã£o baseada em **aptidÃ£o (fitness)**
- Uso de **elitismo**
- AdaptaÃ§Ã£o comportamental a diferentes desafios

Os agentes aprendem sem dados rotulados, apenas por **interaÃ§Ã£o, sobrevivÃªncia e desempenho**.

---

## ğŸ§  Como a IA Funciona

Cada dinossauro Ã© controlado por sua prÃ³pria **rede neural**, que recebe informaÃ§Ãµes do estado do jogo e decide qual aÃ§Ã£o executar em tempo real.

### Entradas da Rede Neural

As entradas representam o estado atual do jogo:

- PosiÃ§Ã£o do jogador `(X, Y)`
- PosiÃ§Ã£o do inimigo `(X, Y)`
- DimensÃµes do inimigo (altura e largura)
- Velocidade do inimigo

![Captura de Tela](Readme/Capturar4.PNG)

Todas as entradas sÃ£o **normalizadas** para manter escalas comparÃ¡veis.

---

### SaÃ­das (AÃ§Ãµes)

As aÃ§Ãµes sÃ£o controladas diretamente pela rede neural:

- Pular
 <img src="Readme/Capturar5.PNG" alt="Captura de Tela" width="350" height="350">

- Agachar
 <img src="Readme/Capturar6.PNG" alt="Captura de Tela" width="350" height="350">

NÃ£o existe lÃ³gica fixa ou regras condicionais.

---

## ğŸ§¬ Aprendizado Evolutivo

O aprendizado ocorre por **evoluÃ§Ã£o**, sem uso de backpropagation.

### ğŸ”„ Ciclo de GeraÃ§Ã£o

1. InicializaÃ§Ã£o da populaÃ§Ã£o
2. Todos os agentes jogam simultaneamente
3. AvaliaÃ§Ã£o por funÃ§Ã£o de aptidÃ£o
4. RemoÃ§Ã£o dos piores agentes
5. PreservaÃ§Ã£o dos melhores por **elitismo**
6. CriaÃ§Ã£o de novos agentes via **mutaÃ§Ã£o** (e cruzamento opcional)
7. RepetiÃ§Ã£o do processo por vÃ¡rias geraÃ§Ãµes

 <img src="Readme/Capturar7.PNG" alt="Captura de Tela" width="450" height="450">

---

## ğŸ† FunÃ§Ã£o de AptidÃ£o

A funÃ§Ã£o de aptidÃ£o recompensa agentes que:

- Sobrevivem por mais tempo
- Evitam colisÃµes
- Reagem corretamente a diferentes tipos de inimigos

SÃ£o avaliados comportamentos contra:

- Inimigos terrestres
- Inimigos voadores

Isso evita estratÃ©gias repetitivas e estimula adaptaÃ§Ã£o.

---

## âš™ï¸ Tecnologias Utilizadas

- Java
- ProgramaÃ§Ã£o Orientada a Objetos (POO)
- Rede Neural implementada do zero
- Algoritmos Evolutivos
- Java Swing (renderizaÃ§Ã£o e loop do jogo)
- SimulaÃ§Ã£o em tempo real

> Nenhuma biblioteca externa de IA ou Machine Learning foi utilizada.

---

## ğŸ§ª Conceitos Aplicados

- Algoritmos Evolutivos
- SeleÃ§Ã£o baseada em aptidÃ£o
- Elitismo
- MutaÃ§Ã£o populacional e individual
- Redes Neurais Multicamadas
- NormalizaÃ§Ã£o de dados
- Sistemas de decisÃ£o em tempo real
- AvaliaÃ§Ã£o por simulaÃ§Ã£o

---

## ğŸ“Š Estado Atual

- âœ… IA evolutiva funcional
- âœ… MÃºltiplas geraÃ§Ãµes simuladas
- âœ… Inimigos dinÃ¢micos e dificuldade crescente
- âœ… Monitoramento de fitness (mÃ­nimo, mÃ¡ximo e mÃ©dio)
- ğŸš§ Ajustes contÃ­nuos de arquitetura e funÃ§Ã£o de aptidÃ£o

---

## ğŸ“Œ ImportÃ¢ncia do Projeto

Este projeto demonstra:

- ImplementaÃ§Ã£o prÃ¡tica de IA sem bibliotecas prontas
- Projeto de sistemas de aprendizado do zero
- DomÃ­nio de computaÃ§Ã£o evolutiva
- ExperiÃªncia com sistemas complexos
- AplicaÃ§Ã£o real de conceitos acadÃªmicos de IA

---

## ğŸ‘¤ Autor

**Guilherme Peres Mundim**  
Graduando em Sistemas de InformaÃ§Ã£o  
Foco em InteligÃªncia Artificial, CiÃªncia de Dados e Engenharia de Software
